[data]
type=data
dataIdx=0

[labels]
type=data
dataIdx=1

#-------------resize layer------------
[resiz]
type=resize
inputs=data
scale=2
channels=3

#------------first layer--------------
# input : 224 x 224 x 3
[conv1-1]
type=conv
inputs=data
channels=3
filters=48
padding=1
stride=4
filterSize=11
initW=0.01
#initW=0.0001
sharedBiases=1
partialSum=1
neuron=relu
# output: 55 x 55 x 48

[pool1-1]
type=pool
pool=max
inputs=conv1-1
start=0
sizeX=3
stride=2
outputsX=0
channels=48
# output: 27 x 27 x 48

[rnorm1-1]
type=cmrnorm
inputs=pool1-1
channels=48
size=5
# output: 27 x 27 x 48

#------------first layer--------------
# input : 224 x 224 x 3
[conv1-2]
type=conv
inputs=resiz
channels=3
filters=48
padding=1
stride=4
filterSize=11
initW=0.01
weightSource=conv1-1
sharedBiases=1
partialSum=1
neuron=relu
# output: 55 x 55 x 48

[pool1-2]
type=pool
pool=max
inputs=conv1-2
start=0
sizeX=3
stride=2
outputsX=0
channels=48
# output: 27 x 27 x 48

[rnorm1-2]
type=cmrnorm
inputs=pool1-2
channels=48
size=5
# output: 27 x 27 x 48

#------------second layer--------------
[conv2-1]
type=conv
inputs=rnorm1-1
channels=48
filters=128
padding=2
stride=1
filterSize=5
neuron=relu
initW=0.01
initB=1
partialSum=1 
# output: 27 x 27 x 128

[pool2-1]
type=pool
pool=max
inputs=conv2-1
start=0
sizeX=3
stride=2
outputsX=0
channels=128
# output: 13 x 13 x 128

[rnorm2-1]
type=cmrnorm
inputs=pool2-1
channels=128
size=5
# output: 13 x 13 x 128

#------------second layer--------------
[conv2-2]
type=conv
inputs=rnorm1-2
channels=48
filters=128
padding=2
stride=1
filterSize=5
neuron=relu
initW=0.01
initB=1
partialSum=1 
# output: 27 x 27 x 128

[pool2-2]
type=pool
pool=max
inputs=conv2-2
start=0
sizeX=3
stride=2
outputsX=0
channels=128
# output: 13 x 13 x 128

[rnorm2-2]
type=cmrnorm
inputs=pool2-2
channels=128
size=5
# output: 13 x 13 x 128

#------------third layer--------------
[conv3-1]
type=conv
inputs=rnorm2-1
channels=128
filters=192
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
partialSum=1
#output: 13 x 13 x 192

#------------third layer--------------
[conv3-2]
type=conv
inputs=rnorm2-2
channels=128
filters=192
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
partialSum=1
#output: 13 x 13 x 192

#------------forth layer--------------
[conv4-1]
type=conv
inputs=conv3-1
channels=192
filters=192
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
initB=1
partialSum=1
#output: 13 x 13 x 192

#------------forth layer--------------
[conv4-2]
type=conv
inputs=conv3-2
channels=192
filters=192
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
initB=1
partialSum=1
#output: 13 x 13 x 192

#------------fifth layer--------------
[conv5-1]
type=conv
inputs=conv4-1
channels=192
filters=128
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
initB=1
partialSum=1
#output: 13 x 13 x 128

[pool5-1]
type=pool
pool=max
inputs=conv5-1
start=0
sizeX=3
stride=2
outputsX=0
channels=128
# output: 6 x 6 x 128

#------------fifth layer--------------
[conv5-2]
type=conv
inputs=conv4-2
channels=192
filters=128
padding=1
stride=1
filterSize=3
neuron=relu
initW=0.01
initB=1
partialSum=1
#output: 13 x 13 x 128

[pool5-2]
type=pool
pool=max
inputs=conv5-2
start=0
sizeX=3
stride=2
outputsX=0
channels=128
# output: 6 x 6 x 128

#------------sixth layer--------------
[fc6]
type=fc
outputs=4096
inputs=pool5-1,pool5-2
initW = 0.01,0.01
initB=1
neuron=relu
# output 4096

#------------seventh layer--------------
[fc7]
type=fc
outputs=4096
inputs=fc6
initW = 0.01
initB=1
neuron=relu
# output 4096

#------------eighth layer----------------
[fc8]
type=fc
#outputs=10
outputs=1000
inputs=fc7
initW = 0.01

[probs]
type=softmax
inputs=fc8

[logprob]
type=cost.logreg
inputs=labels,probs
